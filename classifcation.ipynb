{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with machine learning it never says for certain that the prediction is correct. It only says that this image \n",
    "has the highest probability of being correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimport_ipynb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mall_images\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mML_process\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_images' is not defined"
     ]
    }
   ],
   "source": [
    "# importing all pictures\n",
    "import import_ipynb\n",
    "import testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/Pytorch/Images/Classification.png'\n",
    "classification_image = Image(img, width=750, height=750)\n",
    "classification_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above\n",
    "batch_size is equal to none or 32. \n",
    "* This is saying how many images the computer should look at, at one time\n",
    "* **It is noted that batch size is most efficient while using a number devisable by 8**\n",
    "\n",
    "The number 3 is because we are using 3 layers of classification. \n",
    "Looking at the output we can see that we are trying to determine \n",
    "weather the image that was provided is sushi meat or a pizza.\n",
    "\n",
    "The last 2 layers are the size/dimensions of the image provided width by height.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make classification data and get it ready\n",
    "\n",
    "* The process is the same ML_process that it has always been.\n",
    "* preparing data step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making 1000 samples\n",
    "n_samples = 1000\n",
    "\n",
    "# create circles\n",
    "X, y = make_circles(n_samples,# 1\n",
    "                    noise=0.03, # this is used to create some randomness inside of the code\n",
    "                    random_state=42) ## this is the same as setting a random seed so that we can have re-producible code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"fist 5 of x:\\n {X[:5]}\\n first 5 of y:\\n {y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a DataFrame \n",
    "import pandas as pd\n",
    "circles = pd.DataFrame({\"X1:\": X[:,0],\n",
    "                        \"X2\": X[:,1],\n",
    "                        \"label\":y})\n",
    "circles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at it on a graph\n",
    "plt.scatter(x=X[:,0],\n",
    "            y=X[:,1],\n",
    "            c=y,\n",
    "            cmap=plt.cm.RdYlBu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning data into tensors.\n",
    "* Also step 1 in ML process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going back to the fundamentals one of the most common errors is that the shapes don't match. \n",
    "# So make sure that the input and output match \n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the first example\n",
    "X_sample = X[0]\n",
    "y_sample = y[0]\n",
    "\n",
    "print(f\"values for one sample of x: {X_sample} and the same for y: {y_sample}\")\n",
    "print(f\"Shapes for one sample of x: {X_sample.shape} and the same for y: {y_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning data into tensors\n",
    "# changing into tensor default datatype\n",
    "X = torch.from_numpy(X).type(torch.float32)\n",
    "y = torch.from_numpy(y).type(torch.float32)\n",
    "\n",
    "X[:5], y[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiting the data Training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data randomly\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# must be written in this order if using this method to split data. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # the testing data\n",
    "                                                    y, # labels\n",
    "                                                    test_size=0.2, # how big the test split will be (.2 = 20%)\n",
    "                                                    random_state=42) # set the random seed same as torch.manuel_seed(42)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model\n",
    "\n",
    "Model to classify our blue and red dots\n",
    "\n",
    "To do \n",
    "1. setup device agonistic code so our code will run on an GPU (completed at the top already)\n",
    "2. Construct a model(by subclassing nn.model)\n",
    "3. Define a loss function and optimizer\n",
    "4. Create a training and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device agonistic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a model\n",
    "1. subclass nn.model (almost all pytorch models use this)\n",
    "2. create 2 nn.Linear() layers that are able to handle the shapes of our data\n",
    "3. defines a forward() method that outlines the forward pass (or forward compotation) of hte model\n",
    "4. Insatiate an instance of our model class and send it to the target device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Note that if you have more than one self.layer the in_features of the layer must be the same as the \n",
    "out_features of the previous layer. \n",
    "\n",
    "Out features\n",
    "* This also act like a hidden layer\n",
    "* the more out_features that a model has the more of a chance the computer has to find patterns in the data,\n",
    "but there is a upper limit to this (dimensioning return). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. constructing a model \n",
    "class CircleModelV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. create 2 nn.Linear layers that can handle the shape of the data\n",
    "        # We take in 2 in_features because X_train shape is 2 columns\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=5) # takes in 2 features and out put 5\n",
    "        \n",
    "        # THE IN FEATURES OF THIS LAYER MUST MATCH THE OUT FEATURES OF THE PREVIOUS LAYER\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1) \n",
    "\n",
    "    # 3. defines a forward() method that outlines the forward pass\n",
    "    def forward(self, x):\n",
    "        # Codes backwards but works from the inside out. \n",
    "        return self.layer_2(self.layer_1(x)) # x -> layer_1 -> layer_2 -> output\n",
    "    \n",
    "# Instantiate an instance of our model class and send it to the target device\n",
    "model_0 = CircleModelV0().to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that the model is on the gpu\n",
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a more complex model it is better to use subclassing. (above)\n",
    "* For a simpler model it's better and easier to use sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicating the model above using nn.Sequential()\n",
    "model_0 = nn.Sequential(nn.Linear(in_features=2, out_features=5),\n",
    "                        nn.Linear(in_features=5, out_features=1)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "with torch.inference_mode():\n",
    "    untrained_preds = model_0(X_test.to(device))\n",
    "print(f\"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")\n",
    "print(f\"Length of test sample: {len(X_test)}, Shape: {X_test.shape}\")\n",
    "print(f\"\\n First 10 predictions: \\n{untrained_preds[:10]}\")\n",
    "print(f\"\\n Firs 10 labels: \\n {y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up the loss function\n",
    "picking the loss function \n",
    "* For regression using MAE or MSE will most likely be the way to go\n",
    "* For classification using binary cross entropy or categorical cross entropy will be the way to go\n",
    "\n",
    "Remember loss function measures how wrong th module is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some common loss functions are\n",
    "from IPython.display import Image\n",
    "loss_functions = Image('Images/common_loss_functions.png', width=750, height=750)\n",
    "loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
