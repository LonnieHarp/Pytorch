{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Information\n",
    "- Anytime that you encode data into numbers when using pytorch it is of tensor type. \n",
    "- Typically when dealing with a scalar or vector the data is usually represented as a lower case letter, but for matrix and tensor it is upper case\n",
    "    - scalar(a), vector(y), MATRIX(Q),TENSOR(X) *Note this is just common practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most things works off tensors\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a scalar has no dimensions. So we get back 0\n",
    "scalar.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the tensor back as a int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectors do have dimensions\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MATRIX\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "                       \n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of dimensions is equal to the number of []\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to use print statement if there are more than one per box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor work the same way as an array\n",
    "print(MATRIX[0])\n",
    "MATRIX[1]\n",
    "\n",
    "# can also be printed as a tensor\n",
    "#MATRIX[0], MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the shape is equal to the number of (row,column)\n",
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode each matrix in it's own pair of []. This is so the computer can see that it has 1 bracket of [x,y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR \n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see it action. [1 matrix of [[3,3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Random tensors are used because they most neural networks start with a set of random tensors and then adjust those numbers in a way that \n",
    "the data can be more easily represented. \n",
    "\n",
    "How neural networks work\n",
    "\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8821, 0.2192, 0.3348, 0.0653],\n",
       "        [0.7178, 0.6641, 0.4926, 0.2329],\n",
       "        [0.7626, 0.4003, 0.1482, 0.6840]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random tensor of size(3,4) (size/shape are the same thing)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note that having size here does not matter this is just another way of creating a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with a similar shape to an image tensor\n",
    "random_image_size_tenor = torch.rand(size=(224,224,3))#height, width, color channels(R,G,B)\n",
    "random_image_size_tenor.shape,random_image_size_tenor.ndim #This prints in a tensor format\n",
    "#color channels can also be put first torch.rand(size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype\n",
    "#dtype = data type \n",
    "# the default data type is float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use torch.arange() torch.range is the same thing but an out of data way to do it. \n",
    "one_to_ten = torch.arange(0,10) #includes 0 but, excludes the 10\n",
    "print(one_to_ten)\n",
    "\n",
    "#step is something is goes up by\n",
    "skip_a_few = torch.arange(0,50,5)\n",
    "#skip_a_few = torch.arange(start=0,end=50,step=5) this is the same thing\n",
    "skip_a_few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors like creates a tensor but replaces the numbers with zeros \n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "print(ten_zeros)\n",
    "\n",
    "# same thing but with ones. \n",
    "ten_ones = torch.ones_like(input=skip_a_few)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The tensor is default float 32 but if you need something with more precise then use float64 if less than use float 16\n",
    "\n",
    "Three of the biggest reasons for error are:\n",
    "1. Tensor not of the right data type\n",
    "2. Tensor not of the right shape (linear algebra and matrix theory)\n",
    "3. Tensor not on the right device\n",
    "    - This happens when one of tensors is running on a cpu but the other is on gpu/tpu/cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=None, #what data type is the tensor (float32 or float16)\n",
    "                               device=None, #Default this uses the cpu\n",
    "                               requires_grad=False) #This is for if you want pytorch to track the gradient \n",
    "float_32_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .type(torch.half) == .type(torch.float16). *best practice use float16\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor.type(torch.float64) *float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some operations may cause an error when data types don't match but not always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor.type(torch.int32) *float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information from the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6075, 0.4708, 0.3910, 0.1134],\n",
       "        [0.5470, 0.1177, 0.6211, 0.6817],\n",
       "        [0.8347, 0.8294, 0.3848, 0.4387]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6075, 0.4708, 0.3910, 0.1134],\n",
      "        [0.5470, 0.1177, 0.6211, 0.6817],\n",
      "        [0.8347, 0.8294, 0.3848, 0.4387]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# these can help with checking if the tensor match. \n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1454, 0.6887, 0.3287],\n",
       "        [0.1884, 0.9199, 0.5917],\n",
       "        [0.8309, 0.3123, 0.3431]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_tensor = torch.rand(3,3)\n",
    "device_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if cuda(gpu) is available.\n",
    "#moves the device to cuda(gpu)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Ready to go.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Failed to load\")\n",
    "    device = torch.device(\"cpu\")\n",
    "device_tensor = torch.device(device)\n",
    "device_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#moving bach to cpu\n",
    "device_tensor = torch.device(\"cpu\")\n",
    "device_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors(Tensor Operations)\n",
    "\n",
    "Tensor operations include:\n",
    "\n",
    "Addition\n",
    "\n",
    "Subtraction\n",
    "\n",
    "Multiplication(element-wise)\n",
    "\n",
    "Division\n",
    "\n",
    "Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding: tensor([11, 12, 13])\n",
      "Subtraction: tensor([-9, -8, -7])\n",
      "Multiply: tensor([2, 4, 6])\n",
      "Divide: tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(f\"Adding: {tensor + 10}\")\n",
    "print(f\"Subtraction: {tensor - 10}\")\n",
    "print(f\"Multiply: {tensor * 2}\")\n",
    "print(f\"Divide: {tensor / 10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pytorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n",
    "1. element wise (mulitply by a scalar)\n",
    "2. Dot product\n",
    "\n",
    "**(rows,cols)*\n",
    "\n",
    "This is the the same as from linear algebra and matrix theroy. \n",
    "# Rules\n",
    "1. the inner dimensions must match. for example:\n",
    "    \n",
    "    [1, 2] @ [3, 4] will not compute \n",
    "    \n",
    "    [5, 6] @ [6, 8] will compute\n",
    "2. The resulting matrix will have the shape of the outer dimensions for example:\n",
    "    \n",
    "    (3,4) @ (4,3) The new shape will be (3,3)\n",
    "    \n",
    "    (3,5) @ (5,1) the new shape will be (3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8836],\n",
       "        [0.7254],\n",
       "        [0.9695]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "torch.matmul(torch.rand(3,5), torch.rand(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "tensor * tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])  *  tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product\n",
    "print(tensor,\" * \",  tensor)\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product does (1 * 1)+(2 * 2)+(3 * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing how long each of the codes take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also another way to do matrix multiplication dot product\n",
    "#this takes the same amount of time as above\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will give an error because shapes do not match \n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "#tensor_A @ tensor_B\n",
    "#torch.mm(tensor_A, tensor_B) #mm = matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplying matrix's with shapes that do not match. \n",
    "\n",
    "By using a transpose you can manipulate the shape of the matrix. This will switch the axis of the given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 3, 5],\n",
       "         [2, 4, 6]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.T is the transpose of the original matrix\n",
    "tensor_A.T, tensor_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that the transpose will change the dimensions of the matrix by checking the shape\n",
    "tensor_A.T.shape, tensor_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A @ tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will give the new shape of: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "new_tensor = torch.mm(tensor_A, tensor_B.T)\n",
    "print(f\"This will give the new shape of: {new_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors, min, max, mean, sum. (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "        90, 95])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "x = torch.arange(0,100,random.randint(5,10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in the array:  tensor(95)\n",
      "Minimum value in the array:  tensor(0)\n",
      "Sum of all elements in the array:  tensor(950)\n"
     ]
    }
   ],
   "source": [
    "#Finding the max min and sum\n",
    "max = x.max()\n",
    "min = x.min()\n",
    "sum = x.sum()\n",
    "\n",
    "#another way torch.min(x)... \n",
    "\n",
    "print(\"Maximum value in the array: \", max)\n",
    "print(\"Minimum value in the array: \", min)\n",
    "print(\"Sum of all elements in the array: \", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value in the tensor is: 47.5\n",
      "Second way to get the mean value in the tensor is: 47.5\n"
     ]
    }
   ],
   "source": [
    "# For mean process is slightly different, you have to do this because the datatype's do not match. \n",
    "# when computing it normally it will give you a long but wants a float so you get an error.\n",
    "mean = torch.mean(x.type(torch.float))\n",
    "mean2 = x.type(torch.float32).mean()\n",
    "print(f\"The mean value in the tensor is: {mean}\")\n",
    "print(f\"Second way to get the mean value in the tensor is: {mean2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(19))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the position of where the max/min values are \n",
    "print(x.shape)\n",
    "x.argmin(), x.argmax(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_max = torch.argmax(x)\n",
    "position_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping, Stacking, Squeezing, Unsqueezing, and Permuting tensor\n",
    "\n",
    "* Reshaping - reshapes the tensor in your desired way\n",
    "\n",
    "* View - Returns a view of an input tensor of certain shape but keeps the same memory as the original tensor. \n",
    "\n",
    "* Stacking - combines multiple tensor on top of each other\n",
    "    - .vstack (vertically stacking)\n",
    "    - .hstack (horizontally stacking)\n",
    "\n",
    "* Squeezing - removes single-dimensional entries from the shape of a tensor.\n",
    "\n",
    "* Unsqueezing - adds a new dimension of size 1 to the tensor at the specified position.\n",
    "\n",
    "* Permute - return a view of the input with dimensions permuted(swapped) in a certain way\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Own tensors: torch.Size([9, 1])\n",
      "Reshaped: torch.Size([1, 9])\n",
      "Normal: torch.Size([9])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n"
     ]
    }
   ],
   "source": [
    "# Adding a dimension\n",
    "# x_reshaped = x.reshape(1,7) this won't work because you're trying to push in 9 dimensions into 7 places\n",
    "x_reshaped = x.reshape(1,9) # pushing 9 inputs into 1 dimension\n",
    "x_own_tensors = x.reshape(9,1) # This will put 9 inputs into a their own tensor's \n",
    "print(x_reshaped)\n",
    "\n",
    "print(f\"Own tensors: {x_own_tensors.shape}\")\n",
    "print(f\"Reshaped: {x_reshaped.shape}\")\n",
    "print(f\"Normal: {x.shape}\")\n",
    "print(x_own_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As long as the .reshape(x,y) multiply equal to the shape/size of the original it can be reshaped as such\n",
    "x_test_reshape = x.reshape(3,3)\n",
    "x_test_reshape, x_test_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view will show the same thing as reshape, BUT remember that view keeps the same memory as the original. \n",
    "# WHATEVER CHANGES ARE MADE TO THE OBJECT IN VIEW WILL CHANGE THE ORIGINAL \n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 5., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([1., 5., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example if i change the second number for z, then the the second number in x will change as well. \n",
    "z[:,1] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vstack will stack the following on top of one another in their own tensors.\n",
    "\n",
    "hstack will merge the following into one tensor\n",
    "\n",
    "(v/h)stack([x,x,x], dim=0) 0 is the same as vstack and 1 will take each number and repeat as a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 5., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 5., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 5., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 5., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking tensors\n",
    "\n",
    "x_stacked = torch.vstack([x,x,x,x])\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with dimension: tensor([[1., 5., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Removed dimension: tensor([1., 5., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# drops all dimension that have a size of 1. \n",
    "x_one_dim = x.reshape(1,9)\n",
    "x_squeezed = torch.squeeze(x_one_dim)\n",
    "\n",
    "print(f\"with dimension: {x_one_dim}\")\n",
    "print(f\"Removed dimension: {x_squeezed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [5.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]),\n",
       " tensor([1., 5., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adds in dimensions at the chosen position\n",
    "# must be in range of [-2, 1]\n",
    "# 1/-1 puts all in their own tensors\n",
    "# 0/-2 puts all in one tensor\n",
    "x_unsqueezed = torch.unsqueeze(x,1)\n",
    "x_unsqueezed, x_unsqueezed.shape, x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
